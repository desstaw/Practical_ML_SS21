{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/desstaw/Practical_ML_SS21/blob/main/Assignment8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "enPpiGh6OtvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Exercise Sheet 8**\n",
        "**Group members**\n",
        "\n",
        "Kristina Matz - 7020180\n",
        "\n",
        "Despina Tawadros - 7933844"
      ],
      "metadata": {
        "id": "TwfTDXivOsxm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z1Ybirp3nF7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "#Store the data\n",
        "X = iris.data\n",
        "\n",
        "#Show features\n",
        "print(*iris.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXoxXsjbXC-1",
        "outputId": "1ea6e794-275c-4c6d-d302-8ef21e1bb05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) sepal width (cm) petal length (cm) petal width (cm)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 1\n",
        "\n",
        "1)"
      ],
      "metadata": {
        "id": "1iPiFiXmO7sP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self, lr):\n",
        "    self.lr = lr\n",
        "    \n",
        "\n",
        "  def fit(self, X,Y):\n",
        "    \"\"\"\n",
        "    Linear Regression: Y = mX * c\n",
        "    \"\"\"\n",
        "    self.w = 0\n",
        "    self.b = 0\n",
        "\n",
        "    num_samples = len(X)\n",
        "    epochs = 100000\n",
        "\n",
        "    # Gradient descent\n",
        "    for i in range(epochs):\n",
        "      y_pred = self.predict(X)\n",
        "\n",
        "      error = y_pred - Y\n",
        "\n",
        "\n",
        "      #gradients\n",
        "      dw = (1 / num_samples) * np.dot(X.T,error)\n",
        "      db = (1 / num_samples) * np.sum(error)\n",
        "\n",
        "      \n",
        "      #Calculate and update the new parameters\n",
        "      self.w -= self.lr * dw\n",
        "      self.b -= self.lr * db\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Predict targets using learned parameters\n",
        "    return np.dot(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "1DfpUe1I9NhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of training samples\n",
        "num_train = 100\n",
        "\n",
        "# Get the training set\n",
        "X_train = X[:num_train, :2]\n",
        "Y_train = X[:num_train, 2:]\n",
        "\n",
        "# Get test set\n",
        "X_test = X[num_train:, :2]\n",
        "Y_test = X[num_train:, 2:]\n",
        "\n",
        "# Create regression model and fit to training set\n",
        "learning_rate = 0.001\n",
        "model = LinearRegression(learning_rate)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Predict target features in the test set\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "\"\"\"\n",
        "Mean Squared Error\n",
        "    - Find the difference between the actual y and predicted y value(y = mx + c), for a given x.\n",
        "    - Square this difference.\n",
        "    - Find the mean of the squares for every value in X.\n",
        "\"\"\"\n",
        "difference_array = np.subtract(Y_test, Y_test_pred)\n",
        "squared_array = np.square(difference_array)\n",
        "\n",
        "mse = squared_array.mean()\n",
        "\n",
        "print(\"Mean Squared Error on test set:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8oC9Qv-Uyz6",
        "outputId": "b438748e-923c-4858-c4b4-bd33eae5d81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on test set: 0.6788922425495524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2)"
      ],
      "metadata": {
        "id": "BD_8EsQuGr5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression2:\n",
        "  def __init__(self, lr, regularization=0):\n",
        "    self.lr = lr\n",
        "    self.reg = regularization\n",
        "    \n",
        "\n",
        "  def fit(self, X,Y):\n",
        "    \"\"\"\n",
        "    Linear Regression: Y = mX * c\n",
        "    \"\"\"\n",
        "    self.w = 0\n",
        "    self.b = 0\n",
        "\n",
        "    num_samples = len(X)\n",
        "    epochs = 1000\n",
        "    \n",
        "    if self.reg != 0:\n",
        "      # Gradient descent using L2 regularization\n",
        "      for i in range(epochs):\n",
        "        y_pred = self.predict(X)\n",
        "\n",
        "        error = (y_pred - Y) + self.reg * np.sum(self.w ** 2)\n",
        "\n",
        "\n",
        "        #gradients\n",
        "        dw = (1 / num_samples) * np.dot(X.T,error)\n",
        "        db = (1 / num_samples) * np.sum(error)\n",
        "\n",
        "      \n",
        "        #Calculate and update the new parameters\n",
        "        self.w -= self.lr * dw\n",
        "        self.b -= self.lr * db\n",
        "\n",
        "    else:\n",
        "      # Gradient descent\n",
        "      for i in range(epochs):\n",
        "        y_pred = self.predict(X)\n",
        "\n",
        "        error = y_pred - Y\n",
        "\n",
        "\n",
        "        #gradients\n",
        "        dw = (1 / num_samples) * np.dot(X.T,error)\n",
        "        db = (1 / num_samples) * np.sum(error)\n",
        "\n",
        "      \n",
        "        #Calculate and update the new parameters\n",
        "        self.w -= self.lr * dw\n",
        "        self.b -= self.lr * db\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Predict targets using learned parameters\n",
        "    return np.dot(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "hwG1AoqPGs0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "\n",
        "# Set number of folds\n",
        "num_folds = 5\n",
        "\n",
        "# Define values for regularization\n",
        "choices_C = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "# Create matrix to store validation\n",
        "results = np.empty(len(choices_C))\n",
        "\n",
        "# Partition training set\n",
        "X_train_folds = np.array_split(X_train, num_folds)\n",
        "y_train_folds = np.array_split(Y_train, num_folds)\n",
        "\n",
        "for i, C in enumerate(choices_C):\n",
        "  # Create array to store intermediate results\n",
        "    accuracies = np.empty(num_folds)\n",
        "\n",
        "    # Cross validate hyperparameters setting\n",
        "    for k in range(num_folds):\n",
        "\n",
        "      # Use current fold for validation\n",
        "      X_val = X_train_folds[k]\n",
        "      y_val = y_train_folds[k]\n",
        "\n",
        "      # Use remaining folds as testing set\n",
        "      X_train_concat = np.concatenate(X_train_folds[:k] + X_train_folds[k + 1:])\n",
        "      y_train_concat = np.concatenate(y_train_folds[:k] + y_train_folds[k + 1:])\n",
        "\n",
        "      # Create support vector classifier\n",
        "      model_2 = LinearRegression2(0.0001, C)\n",
        "\n",
        "      # Fit the model to training data\n",
        "      model_2.fit(X_train_concat, y_train_concat)\n",
        "\n",
        "      # Compute accuracy\n",
        "      pred = model_2.predict(X_val)\n",
        "      difference_array = np.subtract(y_val, pred)\n",
        "      squared_array = np.square(difference_array)\n",
        "\n",
        "      mse = squared_array.mean()\n",
        "      accuracies[k] = mse\n",
        "\n",
        "# Get indices of best values\n",
        "i = np.argmin(results)\n",
        "\n",
        "best_C = choices_C[i] # best regularization parameter\n",
        "\n",
        "print(\"Mean Squared Error with regularization parameter\", best_C, \":\", accuracies[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDRQ8wRyGtkx",
        "outputId": "fd9102bf-a3e0-4435-9ea8-b61fe8fb6d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error with regularization parameter 0.1 : 1.9537665392103007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3)"
      ],
      "metadata": {
        "id": "1dV8uagHHFkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression3:\n",
        "  #1. here momentum\n",
        "  def __init__(self, lr, momentum):\n",
        "    self.lr = lr\n",
        "    self.momentum = momentum\n",
        "    \n",
        "\n",
        "  def fit(self, X,Y):\n",
        "    \"\"\"\n",
        "    Linear Regression: Y = mX * c\n",
        "    \"\"\"\n",
        "    self.w = 0\n",
        "    self.b = 0\n",
        "\n",
        "    num_samples = len(X)\n",
        "    epochs = 2\n",
        "\n",
        "    # Gradient descent\n",
        "    for i in range(epochs):\n",
        "      y_pred = self.predict(X)\n",
        "\n",
        "      error = y_pred - Y\n",
        "      \n",
        "      change_dw = 0.0\n",
        "      change_db = 0.0\n",
        "\n",
        "      # Gradients\n",
        "      dw = (1 / num_samples) * np.dot(X.T,error)\n",
        "      db = (1 / num_samples) * np.sum(error)      \n",
        "\n",
        "      \n",
        "      # Calculate and update the new parameters\n",
        "      self.w -= self.lr * dw\n",
        "      self.b -= self.lr * db\n",
        "\n",
        "      new_change_dw = (i * dw) + (momentum * change_dw)\n",
        "      new_change_db = (i * db) + (momentum * change_db)\n",
        "\n",
        "      self.w -= (self.lr * dw) - new_change_dw\n",
        "      self.b -= (self.lr * db) - new_change_db\n",
        "\n",
        "      # Save the change\n",
        "      change_dw = new_change_dw\n",
        "      change_db = new_change_db\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Predict targets using learned parameters\n",
        "    return np.dot(X, self.w) + self.b"
      ],
      "metadata": {
        "id": "5YvHZOXKHGaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set number of training samples\n",
        "num_train = 100\n",
        "\n",
        "# Get the training set\n",
        "X_train = X[:num_train, :2]\n",
        "Y_train = X[:num_train, 2:]\n",
        "\n",
        "# Get test set\n",
        "X_test = X[num_train:, :2]\n",
        "Y_test = X[num_train:, 2:]\n",
        "\n",
        "# Create regression model and fit to training set\n",
        "learning_rate = 0.001\n",
        "momentum = 0.9\n",
        "model = LinearRegression3(learning_rate, momentum)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Predict target features in the test set\n",
        "Y_test_pred = model.predict(X_test)\n",
        "\n",
        "\"\"\"\n",
        "Mean Squared Error\n",
        "    - Find the difference between the actual y and predicted y value(y = mx + c), for a given x.\n",
        "    - Square this difference.\n",
        "    - Find the mean of the squares for every value in X.\n",
        "\"\"\"\n",
        "difference_array = np.subtract(Y_test, Y_test_pred)\n",
        "squared_array = np.square(difference_array)\n",
        "\n",
        "mse = squared_array.mean()\n",
        "\n",
        "print(\"Mean Squared Error on test set:\", mse)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bByvq8fEHI_h",
        "outputId": "ec58811c-5591-475e-ea4a-aa5be4783755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error on test set: 10239.450947111496\n"
          ]
        }
      ]
    }
  ]
}